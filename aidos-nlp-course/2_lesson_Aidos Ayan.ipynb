{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59265d42-f171-4eef-8e0a-2a772239be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['http_proxy'] = \"http://proxy-ws.cbank.kz:8080\"\n",
    "# os.environ['https_proxy'] = \"http://proxy-ws.cbank.kz:8080\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e8f04-2e37-41d0-a47b-5ed78584bc52",
   "metadata": {},
   "source": [
    "<font size=\"12\">Sentenize</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e41da82-27db-41c7-8f2d-4d745dc9ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_en = \"Hello! How are you? I hope you're doing well. Have a great day.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d553be7d-4110-481c-8277-a05a1a23dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ru = '''\n",
    "... - \"Так в чем же дело?\" - \"Не ра-ду-ют\".\n",
    "... И т. д. и т. п. В общем, вся газета\n",
    "... '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f98a84-e5ff-42a5-9b58-24a6c2b4775f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def nltk_sentenize(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f0c903-e8fe-477b-90ac-ee44d1b6fdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!', 'How are you?', \"I hope you're doing well.\", 'Have a great day.']\n",
      "['\\n- \"Так в чем же дело?\"', '- \"Не ра-ду-ют\".', 'И т. д. и т. п. В общем, вся газета']\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk_sentenize(text_en)\n",
    "print(sentences)\n",
    "sentences = nltk_sentenize(text_ru)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1502dacf-7ce2-450e-a60b-c9af51cfa81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: razdel in c:\\users\\ayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fca9f8d-db44-44f1-a80c-ad6d0b10a64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 6, 'Hello!'),\n",
       " Substring(7, 19, 'How are you?'),\n",
       " Substring(20, 45, \"I hope you're doing well.\"),\n",
       " Substring(46, 63, 'Have a great day.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import sentenize\n",
    "sentences =list(sentenize(text_en))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e29f05e-d99b-4e87-9cb3-d783b7fc2b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(1, 23, '- \"Так в чем же дело?\"'),\n",
       " Substring(24, 40, '- \"Не ра-ду-ют\".'),\n",
       " Substring(41, 56, 'И т. д. и т. п.'),\n",
       " Substring(57, 76, 'В общем, вся газета')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences =list(sentenize(text_ru))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe054d-bfa9-4e84-b570-2c05bfb4f1ab",
   "metadata": {},
   "source": [
    "<font size=\"12\">Tokenizer</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0919e8b9-1b4e-4ad1-9580-7f8c9a3a85ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Кружка-термос на 0.5л (50/64 см³, 516;...)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc938b8f-fcc4-4f7b-aeb0-90075cf8cb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8905d0c6-4b36-4573-a051-43b36e724266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Кружка-термос', 'на', '0.5л', '(50/64', 'см³,', '516;...)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10f5524d-ae12-4d9a-91b5-5d20fee3ab4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Кружка-термос',\n",
       " 'на',\n",
       " '0.5л',\n",
       " '(',\n",
       " '50/64',\n",
       " 'см³',\n",
       " ',',\n",
       " '516',\n",
       " ';',\n",
       " '...',\n",
       " ')']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nltk_tokenize(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return words\n",
    "nltk_tokenize(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "860ccd95-8179-430e-b491-e47fd8aecd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 13, 'Кружка-термос'),\n",
       " Substring(14, 16, 'на'),\n",
       " Substring(17, 20, '0.5'),\n",
       " Substring(20, 21, 'л'),\n",
       " Substring(22, 23, '('),\n",
       " Substring(23, 28, '50/64'),\n",
       " Substring(29, 32, 'см³'),\n",
       " Substring(32, 33, ','),\n",
       " Substring(34, 37, '516'),\n",
       " Substring(37, 38, ';'),\n",
       " Substring(38, 41, '...'),\n",
       " Substring(41, 42, ')')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "tokens = list(tokenize(text))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da3b9b-57a3-445b-a3c3-79272f355508",
   "metadata": {},
   "source": [
    "<font size=\"12\">Convert  emoticons to text</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0c689ec-d497-449f-93b2-b20e1983af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             text\n",
      "0  Hello Happy How are you? laugh\n",
      "1            I'm feeling down Sad\n",
      "2         That's hilarious! laugh\n",
      "3        I can't believe it laugh\n",
      "4            This is so sad laugh\n",
      "5            Wink and smile Happy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"Hello :) How are you? :D\",\n",
    "        \"I'm feeling down :(\",\n",
    "        \"That's hilarious! :D\",\n",
    "        \"I can't believe it laugh-)\",\n",
    "        \"This is so sad laugh-(\",\n",
    "        \";) and smile :)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the replacements\n",
    "replacements = [\n",
    "    (r\"\\:\\)\", \"Happy\"),\n",
    "    (r\"\\:\\-\\)\", \"Happy\"),\n",
    "    (r\"\\:\\-\\}\", \"Happy\"),\n",
    "    (r\"\\;\\-\\}\", \"Happy\"),\n",
    "    (r\"\\:\\-\\>\", \"Happy\"),\n",
    "    (r\"\\;\\-\\)\", \"Happy\"),\n",
    "    (r\"\\;\\)\", \"Wink\"),\n",
    "    (r\"\\:\\-\\(\", \"Sad\"),\n",
    "    (r\"\\:\\(\", \"Sad\"),\n",
    "    (r\"\\:\\-\\|\", \"Sad\"),\n",
    "    (r\"\\;\\-\\(\", \"Sad\"),\n",
    "    (r\"\\;\\-\\<\", \"Sad\"),\n",
    "    (r\"\\|\\-\\{\", \"Sad\"),\n",
    "    (r\"\\:\\D\", \"laugh\"),\n",
    "    (r\"\\:\\'\\-\\)\", \"tear of joy\"),\n",
    "    (r\"\\:\\`\\-\\(\", \"tear of sadness\"),\n",
    "    (r\"laugh-\\)\", \"laugh\"),\n",
    "    (r\"laugh-\\(\", \"laugh\")\n",
    "]\n",
    "\n",
    "# Apply the replacements\n",
    "for pattern, replacement in replacements:\n",
    "    df[\"text\"] = df[\"text\"].str.replace(pattern, replacement, regex=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aead00d-b9db-4e82-9cc3-4a143bb576b6",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"12\">Removing punctuation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f35c7eb7-12da-4ba2-a1d6-f594367ab9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world! Hows  everything going\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Define the set of punctuation to exclude\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "# Define the set of punctuation to retain\n",
    "not_exclude = {\".\", \"!\", \",\"}\n",
    "\n",
    "# Determine the final set of punctuation to remove\n",
    "final = exclude - not_exclude\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return ''.join(char for char in text if char not in final)\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello, world! How's ()& everything going?\"\n",
    "cleaned_text = remove_punctuation(text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc5e49-783f-44db-9afb-bce3638ad86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7074581d-4811-4263-b1f6-cdc5ace0075c",
   "metadata": {},
   "source": [
    "<font size=\"12\">Removing stop words</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "870e0d14-85ee-4fa6-9539-31d0529e4c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebee7bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop_words in c:\\users\\ayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2018.7.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d221671-9812-434f-8e54-1b0b7c5a5b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words_en = list(get_stop_words('en'))        \n",
    "nltk_words_en = list(stopwords.words('english')) \n",
    "stop_words_ru = list(get_stop_words('ru'))         \n",
    "nltk_words_ru = list(stopwords.words('russian')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "297861d4-984e-4cb0-9033-2d6ad7d3de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words_en = set(get_stop_words('en')) | set(stopwords.words('english'))\n",
    "#stop_words_ru = set(get_stop_words('ru')) | set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c2ebf05-8eb4-44f9-ad74-6258cb6f911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_en=stop_words_en\n",
    "stop_words_ru=stop_words_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "526b3bea-16cc-45c4-9a9f-4e3574d0dc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence demonstrate removal stopwords.\n",
      "пример предложения демонстрации удаления стоп-слов.\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(text, language='en'):\n",
    "    if language == 'en':\n",
    "        stop_words = stop_words_en\n",
    "    elif language == 'ru':\n",
    "        stop_words = stop_words_ru\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported language. Use 'en' for English or 'ru' for Russian.\")\n",
    "    \n",
    "    return ' '.join(word for word in text.split() if word.lower() not in stop_words)\n",
    "\n",
    "# Example usage\n",
    "english_text = \"This is an example sentence to demonstrate the removal of stopwords.\"\n",
    "russian_text = \"Это пример предложения для демонстрации удаления стоп-слов.\"\n",
    "\n",
    "cleaned_english_text = remove_stopwords(english_text, 'en')\n",
    "print(cleaned_english_text)\n",
    "cleaned_russian_text = remove_stopwords(russian_text, 'ru')\n",
    "print(cleaned_russian_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dba7fc-ded6-49af-aae2-45d96ab538b7",
   "metadata": {},
   "source": [
    "<font size=\"12\">Lemmatizer and Stemmer</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed619680-6d12-438e-b788-d4a88a61a977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Ayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e227f2f-89b3-469f-a329-19176fad7b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kites ---> kite\n",
      "babies ---> baby\n",
      "dogs ---> dog\n",
      "flying ---> flying\n",
      "smiling ---> smiling\n",
      "driving ---> driving\n",
      "died ---> died\n",
      "tried ---> tried\n",
      "feet ---> foot\n",
      "running ---> running\n",
      "are ---> are\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "# Create WordNetLemmatizer object\n",
    "wnl = WordNetLemmatizer()\n",
    " \n",
    "# single word lemmatization examples\n",
    "list1 = ['kites', 'babies', 'dogs', 'flying', 'smiling', \n",
    "         'driving', 'died', 'tried', 'feet', 'running', 'are']\n",
    "for words in list1:\n",
    "    print(words + \" ---> \" + wnl.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaa98a48-de41-4f41-a2fe-446c9f06884a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"running\")\n",
    "doc[0].lemma_\n",
    "# for token in doc:\n",
    "#     print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7d43021-cbaa-48ae-99c1-6b0ddc8e1a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmer.stem(\"running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a22c97dc-ea63-4a91-9506-98e08bbbd784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: running | Stem: run | Lemma: run\n",
      "Word: runs | Stem: run | Lemma: run\n",
      "Word: runner | Stem: runner | Lemma: runner\n",
      "Word: easily | Stem: easili | Lemma: easily\n",
      "Word: fairly | Stem: fairli | Lemma: fairly\n",
      "Word: cats | Stem: cat | Lemma: cat\n",
      "Word: studies | Stem: studi | Lemma: study\n",
      "Word: studying | Stem: studi | Lemma: study\n",
      "Word: better | Stem: better | Lemma: better\n",
      "Word: was | Stem: wa | Lemma: be\n",
      "Word: are | Stem: are | Lemma: be\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a list of words to demonstrate the difference\n",
    "words = [\"running\", \"runs\", \"runner\", \"easily\", \"fairly\", \"cats\", \"studies\", \"studying\", \"better\", \"was\", \"are\"]\n",
    "\n",
    "# Apply stemming and lemmatization\n",
    "stems = [stemmer.stem(word) for word in words]\n",
    "lemmas = [lemmatizer.lemmatize(word, pos='v') for word in words]  # Using 'v' for verb to get accurate results for verbs\n",
    "\n",
    "# Display the results\n",
    "for word, stem, lemma in zip(words, stems, lemmas):\n",
    "    print(f\"Word: {word} | Stem: {stem} | Lemma: {lemma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c77a82d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in c:\\users\\ayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymystem3) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pymystem3) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pymystem3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pymystem3) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pymystem3) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07739b3b-f043-41f9-8013-569cf551edca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Красивая | Lemma: красивый | Stem: красив\n",
      "Word: бегающая | Lemma: бегать | Stem: бега\n",
      "Word: мама | Lemma: мама | Stem: мам\n",
      "Word: красиво | Lemma: красиво | Stem: красив\n",
      "Word: мыла | Lemma: мыть | Stem: мыл\n",
      "Word: раму | Lemma: рама | Stem: рам\n",
      "Word: узнав | Lemma: узнавать | Stem: узна\n",
      "Word: правду | Lemma: правда | Stem: правд\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "\n",
    "# Initialize the Mystem and SnowballStemmer\n",
    "mystem = Mystem()\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "# Input text\n",
    "text = \"Красивая бегающая мама красиво мыла раму узнав правду\"\n",
    "\n",
    "# Perform lemmatization\n",
    "lemmas = mystem.lemmatize(text)\n",
    "lemmas = [lemma.strip() for lemma in lemmas if lemma.strip()]\n",
    "\n",
    "# Perform stemming\n",
    "words = text.split()\n",
    "stems = [stemmer.stem(word) for word in words]\n",
    "\n",
    "# Display the results\n",
    "for word, lemma, stem in zip(words, lemmas, stems):\n",
    "    print(f\"Word: {word} | Lemma: {lemma} | Stem: {stem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd0e8b-81a4-4520-9d4b-c331281365bc",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"12\">Home tasks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf65f8c-a6be-40d6-9593-6c55ec2852f1",
   "metadata": {},
   "source": [
    "<font size=\"5\">1. This task involves normalizing and cleaning a text where some words are replaced with emoticons or the text is split in an unusual way </font>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8fb83b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e4b13bc8-09e7-4a36-94bc-3188c7b14c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Вчера-был просто супер 😊! Проехал 100/160 км, чтобы встре-титься со своим другом. Эго имяАсхат А.Н. ему24г.Это было невероятно круто!Обсуждали все, от программирования-до политики, 2-3часа иливечность за обедом в суши-баре, ХАХА 😂. Потом посмотрели фильмФОрест Г.в кино и заговорили о трендах на рынке и экономических влияниях.Погода? Началось все с  🌞, но вдруг пошел  🌧️. Перед отъездом зашел в уютное кафе за чашкой ☕, очень уютно.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "88f84e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "06e4a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_spellchecker = SpellChecker(language='ru', distance = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "dc10e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(text):\n",
    "    for i in range(len(text)):\n",
    "        if i > 0 and i < (len(text) - 1):\n",
    "            if text[i - 1].isalpha() and text[i + 1].isalpha() and not text[i].isalpha():\n",
    "                text = text.replace(text[i], ' ') \n",
    "                corrected = russian_spellchecker.correction(text)\n",
    "                if corrected: \n",
    "                    text = corrected\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6fceefd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(text):\n",
    "    for i in range(len(text)):\n",
    "        if i > 0 and i < (len(text) - 1):\n",
    "            if text[i - 1].islower() and text[i].isupper():\n",
    "                text = text.replace(text[i], ' ' + text[i]) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e5134b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вчера был просто супер 😊 ! Проехал 100/160 км , чтобы встретиться со своим другом . Эго имя Асхат А . Н . ему 24 г . Это было невероятно круто ! Обсуждали все , от программирования до политики , 2-3 часа иливечность за обедом в суши баре , ХАХА 😂 . Потом посмотрели фильм ФОрест Г . в кино и заговорили о трендах на рынке и экономических влияниях . Погода ? Началось все с 🌞 , но вдруг пошел 🌧️ . Перед отъездом зашел в уютное кафе за чашкой ☕ , очень уютно . '"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text = ''\n",
    "for i in sentenize(text):\n",
    "    for j in tokenize(i.text):\n",
    "        new_text += func2(func(j.text)) + ' '\n",
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2c68b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "   text_normalized = re.sub(r'\\s*\\.\\s*', '.', text)\n",
    "   text_normalized = re.sub(r'\\s*\\!\\s*', '! ', text_normalized)\n",
    "   text_normalized = re.sub(r'\\s*\\,\\s*', ', ', text_normalized)\n",
    "   text = text_normalized\n",
    "   for i in range(len(text)):\n",
    "      if i > 0 and i < (len(text) - 1):\n",
    "         if text[i - 1].isupper() and text[i + 1].islower() and text[i] == '.':\n",
    "            text = text.replace(text[i], text[i] + ' ')\n",
    "   for i in range(len(text)):\n",
    "      if i > 0 and i < (len(text) - 1):\n",
    "         if text[i - 1].isupper() and text[i + 1].islower() and text[i].isupper():\n",
    "            text = text.replace(text[i], text[i].lower())\n",
    " # Capitalize the first letter\n",
    "   return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "89fc396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unions = ['или', 'но']\n",
    "\n",
    "def divide_unions(text):\n",
    "   for union in unions:\n",
    "      if text.startswith(union) or text.endswith(union):\n",
    "         text = text.replace(union, ' ' + union + ' ').strip()\n",
    "         corrected = russian_spellchecker.correction(text)\n",
    "         if corrected: \n",
    "            text = corrected\n",
    "   return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "06847e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вчера был просто супер 😊 ! Проехал 100/160 км , чтобы встретиться со своим другом . Эго имя Асхат А . Н . ему 24 г . Это было невероятно круто ! Обсуждали все , от программирования до политики , 2-3 часа иливечность за обедом в суши баре , ХАХА 😂 . Потом посмотрели фильм ФОрест Г . в кино и заговорили о трендах на рынке и экономических влияниях . Погода ? Началось все с 🌞 , но вдруг пошел 🌧️ . Перед отъездом зашел в уютное кафе за чашкой ☕ , очень уютно . '"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8e575055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вчера был просто супер 😊 ! Проехал 100/160 км , чтобы встретиться со своим другом . Эго имя Асхат А . Н . ему 24 г . Это было невероятно круто ! Обсуждали все , от программирования до политики , 2-3 часа или вечность за обедом в суши баре , ХАХА 😂 . Потом посмотрели фильм ФОрест Г . в кино и заговор или о трендах на рынке и экономических влияниях . Погода ? Началось все с 🌞 , но вдруг пошел 🌧️ . Перед отъездом зашел в уютное кафе за чашкой ☕ , очень уютно . '"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_new_text = ''\n",
    "for i in sentenize(new_text):\n",
    "    for j in tokenize(i.text):\n",
    "        new_new_text += divide_unions(j.text) + ' '\n",
    "new_new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d0b1c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = {\n",
    "    '😊': '',\n",
    "    '😂': 'ВХХЫВХЫХВХЫАХВАВАЫ',\n",
    "    '🌞': 'солнышко',\n",
    "    '🌧️': 'дождь',\n",
    "    '☕':'кофе'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "79d77e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вчера был просто супер  ! Проехал 100/160 км , чтобы встретиться со своим другом . Эго имя Асхат А . Н . ему 24 г . Это было невероятно круто ! Обсуждали все , от программирования до политики , 2-3 часа или вечность за обедом в суши баре , ХАХА ВХХЫВХЫХВХЫАХВАВАЫ . Потом посмотрели фильм ФОрест Г . в кино и заговор или о трендах на рынке и экономических влияниях . Погода ? Началось все с солнышко , но вдруг пошел дождь . Перед отъездом зашел в уютное кафе за чашкой кофе , очень уютно . '"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_new_new_text = ''\n",
    "for i in sentenize(new_new_text):\n",
    "    for j in tokenize(i.text):\n",
    "        word = j.text\n",
    "        if word in emojis:\n",
    "            word = emojis[word]\n",
    "        new_new_new_text += word + ' '\n",
    "new_new_new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e27e5abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вчера был просто супер 😊! Проехал 100/160 км, чтобы встретиться со своим другом. Эго имя Асхат А. Н. ему 24 г. Это было невероятно круто! обсуждали все, от программирования до политики, 2-3 часа или вечность за обедом в суши баре, ХАХА 😂. Потом посмотрели фильм Форест Г. в кино и заговор или о трендах на рынке и экономических влияниях. Погода ? Началось все с 🌞, но вдруг пошел 🌧️. Перед отъездом зашел в уютное кафе за чашкой ☕, очень уютно. \n"
     ]
    }
   ],
   "source": [
    "final_text = normalize_text(new_new_text)\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642556fb-7a2e-4e09-917d-b9d3ff2df455",
   "metadata": {},
   "source": [
    "<font size=\"5\">2. Simple Token-Based Search Using Lemmatization and Stemming. This task involves creating a simple token-based search using lemmatization and stemming techniques. Below is a Python function template that takes a user's input and returns the most relevant sentence from a set of 50 sentences.</font>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5cb5bbff-daa7-450f-b54b-1ba558e346ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "banking_sentences = [\n",
    "    \"The bank offers a variety of savings accounts with different interest rates to suit individual needs.\",\n",
    "    \"Customers can easily transfer money between their accounts using the online banking platform.\",\n",
    "    \"Every month, the bank sends out statements detailing all transactions made during the billing cycle.\",\n",
    "    \"Opening a new account at the bank requires a valid ID and proof of address.\",\n",
    "    \"The bank's mobile app allows users to deposit checks by simply taking a photo with their phone.\",\n",
    "    \"Loans for purchasing homes are available with fixed or variable interest rates.\",\n",
    "    \"Credit cards from the bank come with various rewards programs, including cashback and travel points.\",\n",
    "    \"Bank employees are available to help customers understand their financial statements and plan their budgets.\",\n",
    "    \"Savings accounts can be linked to checking accounts to prevent overdraft fees.\",\n",
    "    \"The bank offers financial advice services to help customers plan for retirement.\",\n",
    "    \"Automatic bill payment services help customers avoid missing due dates for important bills.\",\n",
    "    \"Bank branches provide secure safety deposit boxes for storing valuable items.\",\n",
    "    \"Customers can apply for personal loans to cover unexpected expenses or consolidate debt.\",\n",
    "    \"Online banking allows users to set up alerts for low balances or large transactions.\",\n",
    "    \"The bank provides educational resources to help customers understand how to manage their money.\",\n",
    "    \"Customers can choose from a range of investment options, including stocks and bonds.\",\n",
    "    \"The bank has a dedicated customer service line to assist with any account-related issues.\",\n",
    "    \"Mortgage specialists are available to help first-time homebuyers navigate the process.\",\n",
    "    \"The bank's credit monitoring service alerts customers to any changes in their credit reports.\",\n",
    "    \"Customers can easily update their contact information through the bank's online portal.\",\n",
    "    \"The bank's ATM network provides convenient access to cash withdrawals and deposits.\",\n",
    "    \"Foreign currency exchange services are available for customers planning international travel.\",\n",
    "    \"The bank's fraud protection service monitors accounts for suspicious activity.\",\n",
    "    \"Customers can set spending limits on their credit cards to help manage their budgets.\",\n",
    "    \"The bank offers a range of insurance products, including health, auto, and home insurance.\",\n",
    "    \"Users can download and print monthly account statements directly from the bank's website.\",\n",
    "    \"Small business owners can access loans and lines of credit to help grow their businesses.\",\n",
    "    \"The bank provides secure online payment options for shopping on various e-commerce platforms.\",\n",
    "    \"Mobile banking apps allow users to check their account balances on the go.\",\n",
    "    \"The bank's retirement accounts offer tax advantages to help customers save for the future.\",\n",
    "    \"Financial advisors at the bank can help customers develop long-term investment strategies.\",\n",
    "    \"The bank offers low-interest loans for education and other major life expenses.\",\n",
    "    \"Customers can make international money transfers at competitive exchange rates.\",\n",
    "    \"The bank's secure online platform protects customers' personal and financial information.\",\n",
    "    \"Home equity lines of credit are available for homeowners needing access to cash.\",\n",
    "    \"The bank offers fixed-term deposits with higher interest rates for long-term savings.\",\n",
    "    \"Customers can access their account information 24/7 through the bank's mobile app.\",\n",
    "    \"The bank's customer loyalty programs offer benefits such as reduced fees and higher interest rates.\",\n",
    "    \"Parents can open savings accounts for their children to teach them about money management.\",\n",
    "    \"The bank's budgeting tools help customers track their spending and set financial goals.\",\n",
    "    \"Customers can sign up for direct deposit to have their paychecks automatically deposited.\",\n",
    "    \"The bank offers special accounts for students with no monthly fees and low minimum balances.\",\n",
    "    \"Users can schedule future payments and transfers using the bank's online banking services.\",\n",
    "    \"The bank's investment products include mutual funds and retirement accounts.\",\n",
    "    \"Customers can access financial planning services to help manage their assets and liabilities.\",\n",
    "    \"The bank provides loan calculators to help customers estimate their monthly payments.\",\n",
    "    \"Secure messaging through the bank's online platform allows customers to communicate with their advisors.\",\n",
    "    \"The bank's mobile check deposit feature makes it easy to deposit checks without visiting a branch.\",\n",
    "    \"Customers can earn rewards points for every dollar spent on their credit cards.\",\n",
    "    \"The bank offers personal finance workshops to educate customers on budgeting and saving.\",\n",
    "    \"Customers can track their spending habits using the bank's online expense tracking tools.\",\n",
    "    \"Банк предлагает разнообразные сберегательные счета с разными процентными ставками, чтобы удовлетворить индивидуальные потребности.\",\n",
    "    \"Клиенты могут легко переводить деньги между своими счетами с помощью платформы интернет-банкинга.\",\n",
    "    \"Каждый месяц банк высылает выписки с подробным описанием всех транзакций за отчетный период.\",\n",
    "    \"Открытие нового счета в банке требует действующего удостоверения личности и подтверждения адреса.\",\n",
    "    \"Мобильное приложение банка позволяет пользователям вносить чеки, просто фотографируя их на телефон.\",\n",
    "    \"Кредиты на покупку домов доступны с фиксированными или переменными процентными ставками.\",\n",
    "    \"Кредитные карты банка предлагают различные программы вознаграждений, включая кэшбэк и бонусные баллы для путешествий.\",\n",
    "    \"Сотрудники банка готовы помочь клиентам понять свои финансовые выписки и планировать бюджет.\",\n",
    "    \"Сберегательные счета могут быть связаны с текущими счетами, чтобы предотвратить комиссии за перерасход.\",\n",
    "    \"Банк предлагает услуги финансового консультирования, чтобы помочь клиентам планировать выход на пенсию.\",\n",
    "    \"Услуги автоматической оплаты счетов помогают клиентам избежать пропуска сроков оплаты важных счетов.\",\n",
    "    \"Отделения банка предоставляют безопасные ячейки для хранения ценных вещей.\",\n",
    "    \"Клиенты могут подать заявку на личные кредиты для покрытия непредвиденных расходов или консолидации долгов.\",\n",
    "    \"Интернет-банкинг позволяет пользователям устанавливать уведомления о низких остатках или крупных транзакциях.\",\n",
    "    \"Банк предоставляет образовательные ресурсы, чтобы помочь клиентам понять, как управлять своими деньгами.\",\n",
    "    \"Клиенты могут выбирать из множества инвестиционных опций, включая акции и облигации.\",\n",
    "    \"У банка есть выделенная линия обслуживания клиентов для помощи в любых вопросах, связанных со счетами.\",\n",
    "    \"Специалисты по ипотеке готовы помочь покупателям впервые купить жилье пройти этот процесс.\",\n",
    "    \"Служба мониторинга кредитов банка уведомляет клиентов о любых изменениях в их кредитных отчетах.\",\n",
    "    \"Клиенты могут легко обновить свою контактную информацию через онлайн-портал банка.\",\n",
    "    \"Сеть банкоматов банка обеспечивает удобный доступ к снятию и внесению наличных.\",\n",
    "    \"Услуги обмена иностранной валюты доступны для клиентов, планирующих международные поездки.\",\n",
    "    \"Служба защиты от мошенничества банка отслеживает счета на предмет подозрительной активности.\",\n",
    "    \"Клиенты могут устанавливать лимиты расходов по своим кредитным картам, чтобы помочь управлять бюджетом.\",\n",
    "    \"Банк предлагает разнообразные страховые продукты, включая медицинское, автомобильное и жилищное страхование.\",\n",
    "    \"Пользователи могут загружать и печатать ежемесячные выписки по счетам прямо с сайта банка.\",\n",
    "    \"Малые предприятия могут получить доступ к кредитам и кредитным линиям для роста своих бизнесов.\",\n",
    "    \"Банк предоставляет безопасные онлайн-опции оплаты для покупок на различных платформах электронной коммерции.\",\n",
    "    \"Мобильные банковские приложения позволяют пользователям проверять свои балансы счетов на ходу.\",\n",
    "    \"Пенсионные счета банка предлагают налоговые преимущества, чтобы помочь клиентам сэкономить на будущее.\",\n",
    "    \"Финансовые консультанты банка могут помочь клиентам разработать долгосрочные инвестиционные стратегии.\",\n",
    "    \"Банк предлагает кредиты с низкими процентными ставками для образования и других крупных жизненных расходов.\",\n",
    "    \"Клиенты могут осуществлять международные денежные переводы по конкурентным обменным курсам.\",\n",
    "    \"Безопасная онлайн-платформа банка защищает личную и финансовую информацию клиентов.\",\n",
    "    \"Кредитные линии под залог дома доступны для владельцев домов, нуждающихся в доступе к наличным.\",\n",
    "    \"Банк предлагает депозиты с фиксированным сроком с более высокими процентными ставками для долгосрочных сбережений.\",\n",
    "    \"Клиенты могут получать доступ к информации по счету круглосуточно через мобильное приложение банка.\",\n",
    "    \"Программы лояльности клиентов банка предлагают такие преимущества, как сниженные комиссии и повышенные процентные ставки.\",\n",
    "    \"Родители могут открыть сберегательные счета для своих детей, чтобы научить их управлению деньгами.\",\n",
    "    \"Инструменты составления бюджета банка помогают клиентам отслеживать свои расходы и устанавливать финансовые цели.\",\n",
    "    \"Клиенты могут зарегистрироваться для прямого депозита, чтобы их зарплаты автоматически зачислялись на счет.\",\n",
    "    \"Банк предлагает специальные счета для студентов без ежемесячных комиссий и с низкими минимальными остатками.\",\n",
    "    \"Пользователи могут планировать будущие платежи и переводы, используя услуги интернет-банкинга банка.\",\n",
    "    \"Инвестиционные продукты банка включают взаимные фонды и пенсионные счета.\",\n",
    "    \"Клиенты могут получить доступ к услугам финансового планирования для управления своими активами и обязательствами.\",\n",
    "    \"Банк предоставляет кредитные калькуляторы, чтобы помочь клиентам оценить их ежемесячные платежи.\",\n",
    "    \"Безопасное обмен сообщениями через онлайн-платформу банка позволяет клиентам общаться со своими консультантами.\",\n",
    "    \"Функция мобильного депозита чеков банка позволяет легко вносить чеки без посещения отделения.\",\n",
    "    \"Клиенты могут зарабатывать баллы за вознаграждение за каждый потраченный доллар на своих кредитных картах.\",\n",
    "    \"Банк предлагает семинары по личным финансам, чтобы обучить клиентов составлению бюджета и сбережениям.\",\n",
    "    \"Клиенты могут отслеживать свои привычки трат с помощью онлайн-инструментов отслеживания расходов банка.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "931f1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    for i in text:\n",
    "        if i in exclude:\n",
    "            text = text.replace(i, ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "dcc00148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langdetect \n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "22d7d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_stemmer = SnowballStemmer(language='russian')\n",
    "en_stemmer =  SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "20c6631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b0430a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    language_detected = detect(text)\n",
    "    if language_detected =='ru':\n",
    "        text = text.lower()\n",
    "        text = remove_punctuation(text)\n",
    "        text = [i.text for i in tokenize(text) if i.text not in stop_words_ru]\n",
    "        text = [ru_stemmer.stem(i) for i in text]\n",
    "    else:\n",
    "        text = text.lower()\n",
    "        text = remove_punctuation(text)\n",
    "        text = [i.text for i in tokenize(text) if i.text not in stop_words_en]\n",
    "        text = [en_stemmer.stem(i) for i in text]\n",
    "    return text\n",
    "\n",
    "text_list = [preprocess(i) for i in banking_sentences]\n",
    "len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fbbc1600-d4ce-45b3-a551-6738f57257f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The bank offers a variety of savings accounts with different interest rates to suit individual needs.', 0.5981308411214953, 0)\n",
      "('Parents can open savings accounts for their children to teach them about money management.', 0.5274725274725275, 38)\n",
      "('Loans for purchasing homes are available with fixed or variable interest rates.', 0.5176470588235295, 5)\n",
      "('The bank offers fixed-term deposits with higher interest rates for long-term savings.', 0.5050505050505051, 35)\n",
      "('Savings accounts can be linked to checking accounts to prevent overdraft fees.', 0.4731182795698925, 8)\n"
     ]
    }
   ],
   "source": [
    "def search(query):\n",
    "    query = ' '.join(preprocess(query))\n",
    "    results = []\n",
    "    for i in text_list:\n",
    "        textss = ' '.join(i)\n",
    "        sm=difflib.SequenceMatcher(a=query, b=textss)\n",
    "        idx = text_list.index(i)\n",
    "        results.append((banking_sentences[idx], sm.ratio(), idx))\n",
    "    max_index = sorted(results, key = lambda x: x[1], reverse=True)\n",
    "    return max_index[:5]\n",
    "\n",
    "# Example usage\n",
    "user_query = \"I need saving account with high interest rate\"\n",
    "res = search(user_query)\n",
    "for i in res:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "be55ad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Инвестиционные продукты банка включают взаимные фонды и пенсионные счета.', 0.35294117647058826, 94)\n",
      "('Пенсионные счета банка предлагают налоговые преимущества, чтобы помочь клиентам сэкономить на будущее.', 0.2823529411764706, 80)\n",
      "('У банка есть выделенная линия обслуживания клиентов для помощи в любых вопросах, связанных со счетами.', 0.2702702702702703, 67)\n",
      "('Клиенты могут легко переводить деньги между своими счетами с помощью платформы интернет-банкинга.', 0.2564102564102564, 52)\n",
      "('Клиенты могут зарегистрироваться для прямого депозита, чтобы их зарплаты автоматически зачислялись на счет.', 0.25, 91)\n"
     ]
    }
   ],
   "source": [
    "user_query = \"пенсионный счет\"\n",
    "res = search(user_query)\n",
    "for i in res:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf9e75-201a-499d-b223-3fe733926cef",
   "metadata": {},
   "source": [
    "<font size=\"5\">3. Text Cleaning by Removing Blacklist Words or Phrases</font>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e06efe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "26ff5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "badword_base = ['nigga', 'nigger', 'faggot', 'гей', 'Токаев', 'Путин', 'uzbek']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "36447322",
   "metadata": {},
   "outputs": [],
   "source": [
    "badwords = []\n",
    "for i in badword_base:\n",
    "    badwords.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "08ed3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_word(word):\n",
    "    bigram_word_array = []\n",
    "    for i in range(len(word) - 1):\n",
    "        bigram_word_array.append(word[i: i + 2])\n",
    "    return bigram_word_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e10d2b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_text(text):\n",
    "    tokenized = text.split()\n",
    "    bigram_text_array = [] \n",
    "    for i in range(len(tokenized) - 1):\n",
    "        bigram_text_array.append(' '.join(tokenized[i:i + 2]))\n",
    "    return text.split() + bigram_text_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b7d03223",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramed_words = [bigram_word(i.lower()) for i in badwords]\n",
    "bigram_corpus_set = set(sum(bigramed_words,[]))\n",
    "bigrams_indexed = {}\n",
    "for bigram in bigram_corpus_set:\n",
    "    for index,bigrammed_word in enumerate(bigramed_words):\n",
    "        if bigram in bigrammed_word:\n",
    "            try:\n",
    "                bigrams_indexed[bigram].append(index)\n",
    "            except:\n",
    "                bigrams_indexed[bigram] = []\n",
    "                bigrams_indexed[bigram].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "62596f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_bigram = {}\n",
    "for i in range(len(badwords)):\n",
    "    word_bigram[badwords[i]] = bigramed_words[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "dc46981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bigram(text): \n",
    "    results = []\n",
    "    for word in bigram_text(text):\n",
    "        idx = []\n",
    "        not_found = []\n",
    "        for bigram in bigram_word(word):\n",
    "            try: \n",
    "                idx.extend(bigrams_indexed[bigram])\n",
    "            except:\n",
    "                not_found.append(bigram)\n",
    "        if len(idx):\n",
    "            counted_numbers = Counter(idx)\n",
    "            sorted_numbers = sorted(counted_numbers.items(), key=lambda x: x[1], reverse=True)\n",
    "            coff = (sorted_numbers[0][1])/(len(word_bigram[badwords[sorted_numbers[0][0]]]) + len(not_found))\n",
    "            results.append((word, sorted_numbers, coff))\n",
    "    max_index = max(range(len(results)), key=lambda i: results[i][2])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "c5010f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_thresold(results, threshold):\n",
    "    res = []\n",
    "    results = sorted(results, key=lambda x: x[2], reverse=True)\n",
    "    for word, index, prob in results:\n",
    "        if float(prob) >= float(threshold):\n",
    "            res.append((word, badwords[index[0][0]]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "edafe251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('гей', 'гей'), ('niggas', 'nigga'), ('Токаев', 'Токаев'), ('uzber.', 'uzbek'), ('is niggas', 'nigga'), ('niggas and', 'nigga'), ('and Токаев', 'Токаев'), ('Токаев Тигр', 'Токаев'), ('and гей', 'гей'), ('гей and', 'гей'), ('Тигр uzber.', 'uzbek')]\n"
     ]
    }
   ],
   "source": [
    "query = 'Here is a sample text including the word Путен is niggas and гей and Токаев Тигр uzber.' \n",
    "results = find_bigram(query)\n",
    "valid_badword = []\n",
    "res = take_thresold(results, 0.2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "995f7c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a sample text including the word Путен is *** and *** and *** Тигр ***\n"
     ]
    }
   ],
   "source": [
    "for word, _ in res:\n",
    "    query = query.replace(word, '***')\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d5a34dff-6233-4ef9-866e-5dd21046049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(query):\n",
    "    results = find_bigram(query)\n",
    "    valid_badword = []\n",
    "    res = take_thresold(results, 0.2)\n",
    "    for word, _ in res:\n",
    "        query = query.replace(word, '***')\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d002948d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you black ***'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('you black nigger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18656c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
