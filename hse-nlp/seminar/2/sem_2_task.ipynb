{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "1. Мы будем работать с (частичными) данными lenta.ru отсюда: https://www.kaggle.com/yutkin/corpus-of-russian-news-articles-from-lenta/\n",
    "2. Проведите препроцессинг текста. Разбейте данные на train и test для задачи классификации (в качестве метки класса будем использовать поле topic). В качестве данных для классификации в пунктах 3 и 5 возьмите\n",
    "    - только заголовки (title)\n",
    "    - только тексты новости (text)\n",
    "    - и то, и другое\n",
    "3. Обучите fastText для классификации текстов по темам. Сравните качество для разных данных из п. 2.\n",
    "4. Обучите свою модель w2v (или возьмите любую подходящую предобученную модель). Реализуйте функцию для вычисления вектора текста / заголовка / текста+заголовка как среднего вектора входящих в него слов. \n",
    "     - (Бонус) Модифицируйте функцию вычисления среднего вектора: взвешивайте вектора слов соответствующими весами tf-idf.\n",
    "5. Обучите на полученных средних векторах алгоритм классификации, сравните полученное качество с классификатором fastText. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d yutkin/corpus-of-russian-news-articles-from-lenta\n",
    "# !unzip data/corpus-of-russian-news-articles-from-lenta.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39358/2454759729.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lenta = pd.read_csv(data_path + 'lenta-ru-news.csv', usecols=['title', 'text', 'topic'])\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/'\n",
    "\n",
    "lenta = pd.read_csv(data_path + 'lenta-ru-news.csv', usecols=['title', 'text', 'topic'])\n",
    "lenta = lenta[lenta['topic'].notna()]\n",
    "\n",
    "lenta = lenta.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(738973, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Мир': 0,\n",
       " 'Наука и техника': 1,\n",
       " 'Культура': 2,\n",
       " 'Силовые структуры': 3,\n",
       " 'Россия': 4,\n",
       " 'Спорт': 5,\n",
       " 'Бизнес': 6,\n",
       " 'Путешествия': 7,\n",
       " 'Бывший СССР': 8,\n",
       " 'Дом': 9,\n",
       " 'Экономика': 10,\n",
       " 'Интернет и СМИ': 11,\n",
       " 'Из жизни': 12,\n",
       " 'Ценности': 13,\n",
       " 'Культпросвет ': 14,\n",
       " '69-я параллель': 15,\n",
       " 'Крым': 16,\n",
       " 'Библиотека': 17,\n",
       " 'Легпром': 18,\n",
       " 'Оружие': 19,\n",
       " 'МедНовости': 20,\n",
       " 'ЧМ-2014': 21,\n",
       " 'Сочи': 22}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "\n",
    "for i, topic in enumerate(lenta['topic'].unique()):\n",
    "    label_dict[topic] = i\n",
    "\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "4     160445\n",
       "0     136621\n",
       "10     79528\n",
       "5      64413\n",
       "2      53797\n",
       "8      53402\n",
       "1      53136\n",
       "11     44663\n",
       "12     27605\n",
       "9      21734\n",
       "3      19596\n",
       "13      7766\n",
       "6       7399\n",
       "7       6408\n",
       "15      1268\n",
       "16       666\n",
       "14       340\n",
       "18       114\n",
       "17        65\n",
       "19         3\n",
       "21         2\n",
       "20         1\n",
       "22         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenta['label'] = lenta['topic'].apply(lambda x: label_dict[x])\n",
    "\n",
    "lenta['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "tokenizer = tokenize.NLTKWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n",
      "[nltk_data]     Temporary failure in name resolution>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "noise = stopwords.words('russian') + list(punctuation)\n",
    "splitters = ['\\'\\'', '``', '\\\"', '-', '\\'', '\\`']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'дерево'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy3\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "def morphling_lemmatizer(word):\n",
    "    parsed_word = morph.parse(word)[0]\n",
    "    lemma = parsed_word.normal_form\n",
    "    return lemma\n",
    "\n",
    "morphling_lemmatizer('деревьев')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'задержан'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowball_stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "def ru_stemmer(word):\n",
    "    return snowball_stemmer.stem(word)\n",
    "\n",
    "ru_stemmer('задержание')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'открыть карта'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(sentence): \n",
    "    for splitter in splitters:\n",
    "        sentence = sentence.replace(splitter, ' ')  \n",
    "    tokens = tokenizer.tokenize(sentence.lower())  \n",
    "    clean_tokens = [token.strip() for token in tokens if token not in noise]\n",
    "    lemma_tokens = [morphling_lemmatizer(token) for token in clean_tokens]  \n",
    "    # stemmed_tokens = [ru_stemmer(token) for token in clean_tokens]\n",
    "    return ' '.join(lemma_tokens)\n",
    "\n",
    "preprocess('как открыть карты')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemma - 77\n",
    "# stemm - 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing titles ...: 100%|██████████| 100000/100000 [00:52<00:00, 1907.16it/s]\n",
      "Preprocessing text ...: 100%|██████████| 100000/100000 [19:20<00:00, 86.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "title_preprocessed = [preprocess(str(sentence)) for sentence in tqdm(lenta['title'], desc='Preprocessing titles ...')]\n",
    "text_preprocessed = [preprocess(str(sentence)) for sentence in tqdm(lenta['text'], desc='Preprocessing text ...')]\n",
    "\n",
    "preprocessed_lenta = pd.DataFrame({\n",
    "    'title' : title_preprocessed,\n",
    "    'text' : text_preprocessed,\n",
    "    'label' : lenta['label']\n",
    "})\n",
    "\n",
    "preprocessed_lenta.to_csv(data_path + 'preprocessed_lenta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_test_and_save_train(X_df, y_df, train_path):\n",
    "    X, y = X_df.tolist(), y_df.tolist()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "    with open(data_path + train_path + '.txt', 'w', encoding='utf-8') as file:\n",
    "        for X_entry, y_entry in zip(X_train, y_train):\n",
    "            X_entry = str(X_entry).replace('\\n', ' ').replace('\\r', ' ')\n",
    "            file.write('__label__' + str(y_entry) + ' ' + X_entry)\n",
    "            file.write('\\n')\n",
    "\n",
    "    return X_test, y_test\n",
    "            \n",
    "X_test, y_test = get_test_and_save_train(preprocessed_lenta['text'], preprocessed_lenta['label'], train_path='lenta_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/facebookresearch/fastText.git\n",
    "# ! pip3 install fastText/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 10M words\n",
      "Number of words:  282995\n",
      "Number of labels: 19\n",
      "Progress: 100.0% words/sec/thread: 1122841 lr:  0.000000 avg.loss:  0.101565 ETA:   0h 0m 0s 57.3% words/sec/thread: 1138867 lr:  0.213359 avg.loss:  0.163717 ETA:   0h 0m50s 74.0% words/sec/thread: 1138807 lr:  0.129787 avg.loss:  0.131436 ETA:   0h 0m30s 88.6% words/sec/thread: 1126190 lr:  0.057134 avg.loss:  0.112834 ETA:   0h 0m13s\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "ft_model = fasttext.train_supervised(\n",
    "    input=data_path+'lenta_train.txt',\n",
    "    label='__label__',\n",
    "    lr=0.5,\n",
    "    epoch=25,\n",
    "    wordNgrams=2, \n",
    "    dim=200,\n",
    "    thread=2,\n",
    "    verbose=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('__label__1',)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = ft_model.predict('армия')[0]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = ft_model.predict(X_test)[0]\n",
    "predicted_labels = [int(label[0][9:]) for label in predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8232\n",
      "Precision score:  0.8210461749732852\n",
      "Recall score:  0.8232\n",
      "f1-score:  0.8211251563795954\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      4521\n",
      "           1       0.84      0.85      0.84      1877\n",
      "           2       0.87      0.89      0.88      1792\n",
      "           3       0.72      0.59      0.65       671\n",
      "           4       0.80      0.84      0.82      5471\n",
      "           5       0.97      0.96      0.96      2187\n",
      "           6       0.64      0.49      0.56       279\n",
      "           7       0.78      0.69      0.73       211\n",
      "           8       0.85      0.80      0.82      1787\n",
      "           9       0.87      0.83      0.85       695\n",
      "          10       0.84      0.86      0.85      2692\n",
      "          11       0.77      0.73      0.75      1541\n",
      "          12       0.66      0.59      0.62       926\n",
      "          13       0.89      0.81      0.85       265\n",
      "          14       0.00      0.00      0.00         5\n",
      "          15       0.93      0.33      0.48        40\n",
      "          16       0.33      0.08      0.13        25\n",
      "          17       0.00      0.00      0.00         3\n",
      "          18       0.00      0.00      0.00        11\n",
      "          19       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.82     25000\n",
      "   macro avg       0.63      0.56      0.58     25000\n",
      "weighted avg       0.82      0.82      0.82     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, predicted_labels))\n",
    "print(\"Precision score: \", precision_score(y_test, predicted_labels, average='weighted'))\n",
    "print(\"Recall score: \", recall_score(y_test, predicted_labels, average='weighted'))\n",
    "print(\"f1-score: \", f1_score(y_test, predicted_labels, average='weighted'))\n",
    "\n",
    "report = classification_report(y_test, predicted_labels)\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
