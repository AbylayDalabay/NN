{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "1. Мы будем работать с (частичными) данными lenta.ru отсюда: https://www.kaggle.com/yutkin/corpus-of-russian-news-articles-from-lenta/\n",
    "2. Проведите препроцессинг текста. Разбейте данные на train и test для задачи классификации (в качестве метки класса будем использовать поле topic). В качестве данных для классификации в пунктах 3 и 5 возьмите\n",
    "    - только заголовки (title)\n",
    "    - только тексты новости (text)\n",
    "    - и то, и другое\n",
    "3. Обучите fastText для классификации текстов по темам. Сравните качество для разных данных из п. 2.\n",
    "4. Обучите свою модель w2v (или возьмите любую подходящую предобученную модель). Реализуйте функцию для вычисления вектора текста / заголовка / текста+заголовка как среднего вектора входящих в него слов. \n",
    "     - (Бонус) Модифицируйте функцию вычисления среднего вектора: взвешивайте вектора слов соответствующими весами tf-idf.\n",
    "5. Обучите на полученных средних векторах алгоритм классификации, сравните полученное качество с классификатором fastText. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget -O lenta-ru-news-part.csv https://www.dropbox.com/s/ja23c9l1ppo9ix7/lenta-ru-news-part.csv?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3160\\1630857117.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lenta = pd.read_csv('lenta-ru-news.csv', usecols=['title', 'text', 'topic'])\n"
     ]
    }
   ],
   "source": [
    "lenta = pd.read_csv('lenta-ru-news.csv', usecols=['title', 'text', 'topic'])\n",
    "lenta = lenta[lenta['topic'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(738973, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Библиотека': 0,\n",
       " 'Россия': 1,\n",
       " 'Мир': 2,\n",
       " 'Экономика': 3,\n",
       " 'Интернет и СМИ': 4,\n",
       " 'Спорт': 5,\n",
       " 'Культура': 6,\n",
       " 'Из жизни': 7,\n",
       " 'Силовые структуры': 8,\n",
       " 'Наука и техника': 9,\n",
       " 'Бывший СССР': 10,\n",
       " 'Дом': 11,\n",
       " 'Сочи': 12,\n",
       " 'ЧМ-2014': 13,\n",
       " 'Путешествия': 14,\n",
       " 'Ценности': 15,\n",
       " 'Легпром': 16,\n",
       " 'Бизнес': 17,\n",
       " 'МедНовости': 18,\n",
       " 'Оружие': 19,\n",
       " '69-я параллель': 20,\n",
       " 'Культпросвет ': 21,\n",
       " 'Крым': 22}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "\n",
    "for i, topic in enumerate(lenta['topic'].unique()):\n",
    "    label_dict[topic] = i\n",
    "\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import tokenize\n",
    "\n",
    "# tokenizer = tokenize.NLTKWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# from string import punctuation\n",
    "\n",
    "# noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymorphy3\n",
    "# morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "# def morphling_lemmatizer(word):\n",
    "#     parsed_word = morph.parse(word)[0]\n",
    "#     lemma = parsed_word.normal_form\n",
    "\n",
    "#     return lemma\n",
    "\n",
    "# morphling_lemmatizer('деревьев')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import SnowballStemmer\n",
    "\n",
    "# snowball_stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "# def ru_stemmer(word):\n",
    "#     return snowball_stemmer.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(sentence):\n",
    "#     token_sentence = tokenizer.tokenize(sentence)   \n",
    "#     clean_tokens = [token for token in token_sentence if token not in noise]\n",
    "#     #lemma_sentence = [morphling_lemmatizer(token) for token in clean_tokens]  \n",
    "#     stemmed_sentence = [ru_stemmer(token) for token in clean_tokens]\n",
    "#     return stemmed_sentence\n",
    "\n",
    "# preprocess('как купить много деревьев')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# title_preprocessed = [str(sentence).lower() for sentence in tqdm(lenta['title'], desc='Preprocessing titles ...')]\n",
    "# text_preprocessed = [str(sentence).lower() for sentence in tqdm(lenta['text'], desc='Preprocessing text ...')]\n",
    "\n",
    "# preprocessed_lenta = pd.DataFrame({\n",
    "#     'title' : title_preprocessed,\n",
    "#     'text' : text_preprocessed,\n",
    "#     'topic' : lenta['topic']\n",
    "# })\n",
    "\n",
    "# preprocessed_lenta.to_csv('preprocessed_lenta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta['label'] = lenta['topic'].apply(lambda x: label_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Россия               160445\n",
       "Мир                  136621\n",
       "Экономика             79528\n",
       "Спорт                 64413\n",
       "Культура              53797\n",
       "Бывший СССР           53402\n",
       "Наука и техника       53136\n",
       "Интернет и СМИ        44663\n",
       "Из жизни              27605\n",
       "Дом                   21734\n",
       "Силовые структуры     19596\n",
       "Ценности               7766\n",
       "Бизнес                 7399\n",
       "Путешествия            6408\n",
       "69-я параллель         1268\n",
       "Крым                    666\n",
       "Культпросвет            340\n",
       "Легпром                 114\n",
       "Библиотека               65\n",
       "Оружие                    3\n",
       "ЧМ-2014                   2\n",
       "МедНовости                1\n",
       "Сочи                      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenta['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_test_and_save_train(X_df, y_df, train_path):\n",
    "    X, y = X_df.tolist(), y_df.tolist()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "    with open(train_path+'.txt', 'w', encoding='utf-8') as file:\n",
    "        for X_entry, y_entry in zip(X_train, y_train):\n",
    "            X_entry = str(X_entry).replace('\\n', ' ').replace('\\r', ' ')\n",
    "            file.write('__label__' + str(y_entry) + ' ' + X_entry)\n",
    "            file.write('\\n')\n",
    "\n",
    "    return X_test, y_test\n",
    "            \n",
    "X_test, y_test = get_test_and_save_train(lenta['title'], lenta['label'], train_path='lenta_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "ft_model = fasttext.train_supervised(\n",
    "    input='lenta_train.txt',\n",
    "    label='__label__',\n",
    "    lr=0.5,\n",
    "    epoch=75,\n",
    "    wordNgrams=2, \n",
    "    dim=200,\n",
    "    thread=2,\n",
    "    verbose=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('__label__2',)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = ft_model.predict('армия')[0]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = ft_model.predict(X_test)[0]\n",
    "predicted_labels = [int(label[0][9:]) for label in predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7436560862599056\n",
      "Precision score:  0.748404059050117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score:  0.7436560862599056\n",
      "f1-score:  0.743832903247207\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.73        19\n",
      "           1       0.73      0.77      0.75     40517\n",
      "           2       0.73      0.78      0.76     34008\n",
      "           3       0.76      0.78      0.77     19749\n",
      "           4       0.72      0.64      0.68     11207\n",
      "           5       0.94      0.92      0.93     16047\n",
      "           6       0.80      0.80      0.80     13469\n",
      "           7       0.57      0.43      0.49      6938\n",
      "           8       0.56      0.35      0.43      4950\n",
      "           9       0.75      0.75      0.75     13223\n",
      "          10       0.78      0.80      0.79     13230\n",
      "          11       0.77      0.69      0.73      5368\n",
      "          12       0.00      0.00      0.00         0\n",
      "          14       0.61      0.47      0.53      1561\n",
      "          15       0.79      0.60      0.68      2014\n",
      "          16       0.60      0.11      0.19        27\n",
      "          17       0.52      0.30      0.38      1867\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.63      0.26      0.37       318\n",
      "          21       0.21      0.06      0.10        65\n",
      "          22       0.56      0.35      0.43       166\n",
      "\n",
      "    accuracy                           0.74    184744\n",
      "   macro avg       0.62      0.50      0.54    184744\n",
      "weighted avg       0.75      0.74      0.74    184744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, predicted_labels))\n",
    "print(\"Precision score: \", precision_score(y_test, predicted_labels, average='weighted'))\n",
    "print(\"Recall score: \", recall_score(y_test, predicted_labels, average='weighted'))\n",
    "print(\"f1-score: \", f1_score(y_test, predicted_labels, average='weighted'))\n",
    "\n",
    "report = classification_report(y_test, predicted_labels)\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
