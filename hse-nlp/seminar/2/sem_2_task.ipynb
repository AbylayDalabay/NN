{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "1. Мы будем работать с (частичными) данными lenta.ru отсюда: https://www.kaggle.com/yutkin/corpus-of-russian-news-articles-from-lenta/\n",
    "2. Проведите препроцессинг текста. Разбейте данные на train и test для задачи классификации (в качестве метки класса будем использовать поле topic). В качестве данных для классификации в пунктах 3 и 5 возьмите\n",
    "    - только заголовки (title)\n",
    "    - только тексты новости (text)\n",
    "    - и то, и другое\n",
    "3. Обучите fastText для классификации текстов по темам. Сравните качество для разных данных из п. 2.\n",
    "4. Обучите свою модель w2v (или возьмите любую подходящую предобученную модель). Реализуйте функцию для вычисления вектора текста / заголовка / текста+заголовка как среднего вектора входящих в него слов. \n",
    "     - (Бонус) Модифицируйте функцию вычисления среднего вектора: взвешивайте вектора слов соответствующими весами tf-idf.\n",
    "5. Обучите на полученных средних векторах алгоритм классификации, сравните полученное качество с классификатором fastText. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d yutkin/corpus-of-russian-news-articles-from-lenta\n",
    "# !unzip data/corpus-of-russian-news-articles-from-lenta.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4307/2454759729.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lenta = pd.read_csv(data_path + 'lenta-ru-news.csv', usecols=['title', 'text', 'topic'])\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/'\n",
    "\n",
    "lenta = pd.read_csv(data_path + 'lenta-ru-news.csv', usecols=['title', 'text', 'topic'])\n",
    "lenta = lenta[lenta['topic'].notna()]\n",
    "\n",
    "lenta = lenta.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(738973, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Мир': 0,\n",
       " 'Наука и техника': 1,\n",
       " 'Культура': 2,\n",
       " 'Силовые структуры': 3,\n",
       " 'Россия': 4,\n",
       " 'Спорт': 5,\n",
       " 'Бизнес': 6,\n",
       " 'Путешествия': 7,\n",
       " 'Бывший СССР': 8,\n",
       " 'Дом': 9,\n",
       " 'Экономика': 10,\n",
       " 'Интернет и СМИ': 11,\n",
       " 'Из жизни': 12,\n",
       " 'Ценности': 13,\n",
       " 'Культпросвет ': 14,\n",
       " '69-я параллель': 15,\n",
       " 'Крым': 16,\n",
       " 'Библиотека': 17,\n",
       " 'Легпром': 18,\n",
       " 'Оружие': 19,\n",
       " 'МедНовости': 20,\n",
       " 'ЧМ-2014': 21,\n",
       " 'Сочи': 22}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "\n",
    "for i, topic in enumerate(lenta['topic'].unique()):\n",
    "    label_dict[topic] = i\n",
    "\n",
    "lenta['label'] = lenta['topic'].apply(lambda x: label_dict[x])\n",
    "\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "tokenizer = tokenize.NLTKWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dalabaya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "noise = stopwords.words('russian') + list(punctuation)\n",
    "splitters = ['\\'\\'', '``', '\\\"', '-', '\\'', '\\`']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'дерево'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy3\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "def morphling_lemmatizer(word):\n",
    "    parsed_word = morph.parse(word)[0]\n",
    "    lemma = parsed_word.normal_form\n",
    "    return lemma\n",
    "\n",
    "morphling_lemmatizer('деревьев')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'задержан'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowball_stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "def ru_stemmer(word):\n",
    "    return snowball_stemmer.stem(word)\n",
    "\n",
    "ru_stemmer('задержание')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'открыть карта'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(sentence): \n",
    "    for splitter in splitters:\n",
    "        sentence = sentence.replace(splitter, ' ')  \n",
    "    tokens = tokenizer.tokenize(sentence.lower())  \n",
    "    clean_tokens = [token.strip() for token in tokens if token not in noise]\n",
    "    lemma_tokens = [morphling_lemmatizer(token) for token in clean_tokens]  \n",
    "    # stemmed_tokens = [ru_stemmer(token) for token in clean_tokens]\n",
    "    return ' '.join(lemma_tokens)\n",
    "\n",
    "preprocess('как открыть карты')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save():\n",
    "    title_preprocessed = [preprocess(str(sentence)) for sentence in tqdm(lenta['title'], desc='Preprocessing titles ...')]\n",
    "    text_preprocessed = [preprocess(str(sentence)) for sentence in tqdm(lenta['text'], desc='Preprocessing text ...')]\n",
    "\n",
    "    preprocessed_lenta = pd.DataFrame({\n",
    "        'title' : title_preprocessed,\n",
    "        'text' : text_preprocessed,\n",
    "        'label' : lenta['label']\n",
    "    })\n",
    "\n",
    "    preprocessed_lenta.to_csv(data_path + 'preprocessed_lenta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_and_save_train(X_df, y_df, train_path):\n",
    "    X, y = X_df.tolist(), y_df.tolist()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "    with open(data_path + train_path + '.txt', 'w', encoding='utf-8') as file:\n",
    "        for X_entry, y_entry in zip(X_train, y_train):\n",
    "            X_entry = str(X_entry).replace('\\n', ' ').replace('\\r', ' ')\n",
    "            file.write('__label__' + str(y_entry) + ' ' + X_entry)\n",
    "            file.write('\\n')\n",
    "\n",
    "    return X_test, y_test\n",
    "\n",
    "preprocessed_lenta = pd.read_csv(data_path+'preprocessed_lenta.csv')\n",
    "\n",
    "X_test, y_test = get_test_and_save_train(preprocessed_lenta['text'], preprocessed_lenta['label'], train_path='lenta_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/facebookresearch/fastText.git\n",
    "# ! pip3 install fastText/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 79M words\n",
      "Number of words:  835630\n",
      "Number of labels: 22\n",
      "Progress:   0.6% words/sec/thread:  885059 lr:  0.496773 avg.loss:  1.102168 ETA:   0h18m29s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% words/sec/thread: 1099731 lr:  0.000000 avg.loss:  0.076652 ETA:   0h 0m 0s  6.8% words/sec/thread:  987053 lr:  0.465807 avg.loss:  0.536746 ETA:   0h15m33s  6.9% words/sec/thread:  988233 lr:  0.465365 avg.loss:  0.534122 ETA:   0h15m31s  7.3% words/sec/thread:  993596 lr:  0.463265 avg.loss:  0.522071 ETA:   0h15m21s\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "ft_model = fasttext.train_supervised(\n",
    "    input=data_path+'lenta_train.txt',\n",
    "    label='__label__',\n",
    "    lr=0.5,\n",
    "    epoch=25,\n",
    "    wordNgrams=2, \n",
    "    dim=200,\n",
    "    thread=2,\n",
    "    verbose=3000\n",
    ")\n",
    "\n",
    "ft_model.save_model(data_path+'lenta_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('__label__1',)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.predict('армия')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_df, test_label, selected_model, desc='Unknown parameters model'):\n",
    "    predicted_labels = selected_model.predict(test_df)[0]\n",
    "    predicted_labels = [int(label[0][9:]) for label in predicted_labels]\n",
    "\n",
    "    print(desc, ' => predictions')\n",
    "    print(\"Accuracy score: \", accuracy_score(test_label, predicted_labels))\n",
    "    print(\"Precision score: \", precision_score(test_label, predicted_labels, average='weighted'))\n",
    "    print(\"Recall score: \", recall_score(test_label, predicted_labels, average='weighted'))\n",
    "    print(\"f1-score: \", f1_score(test_label, predicted_labels, average='weighted'))\n",
    "\n",
    "    report = classification_report(test_label, predicted_labels)\n",
    "    print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "saved_model = fasttext.load_model(data_path+'lenta_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma on title and text columns, fastText  predictions\n",
      "Accuracy score:  0.86475880136838\n",
      "Precision score:  0.8641386185876371\n",
      "Recall score:  0.86475880136838\n",
      "f1-score:  0.8641073965617476\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85     33962\n",
      "           1       0.88      0.89      0.89     13271\n",
      "           2       0.90      0.90      0.90     13507\n",
      "           3       0.80      0.71      0.75      4876\n",
      "           4       0.85      0.86      0.86     40259\n",
      "           5       0.97      0.97      0.97     16134\n",
      "           6       0.74      0.64      0.69      1816\n",
      "           7       0.85      0.78      0.81      1577\n",
      "           8       0.88      0.88      0.88     13191\n",
      "           9       0.91      0.88      0.90      5446\n",
      "          10       0.89      0.89      0.89     20004\n",
      "          11       0.82      0.79      0.81     11248\n",
      "          12       0.72      0.68      0.70      6855\n",
      "          13       0.93      0.89      0.91      1962\n",
      "          14       0.50      0.21      0.30        90\n",
      "          15       0.87      0.59      0.70       313\n",
      "          16       0.73      0.58      0.64       182\n",
      "          17       1.00      0.37      0.54        19\n",
      "          18       0.89      0.55      0.68        31\n",
      "          22       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.86    184744\n",
      "   macro avg       0.80      0.70      0.73    184744\n",
      "weighted avg       0.86      0.86      0.86    184744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(X_test, y_test, saved_model, desc='Lemma on title and text columns, fastText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
